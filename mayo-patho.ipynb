{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import openslide\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport cv2\nimport ast\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow_addons as tfa","metadata":{"execution":{"iopub.status.busy":"2022-09-27T04:46:52.569360Z","iopub.execute_input":"2022-09-27T04:46:52.570268Z","iopub.status.idle":"2022-09-27T04:46:58.683499Z","shell.execute_reply.started":"2022-09-27T04:46:52.570071Z","shell.execute_reply":"2022-09-27T04:46:58.682219Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install h5py","metadata":{"execution":{"iopub.status.busy":"2022-09-27T04:46:58.689669Z","iopub.execute_input":"2022-09-27T04:46:58.692782Z","iopub.status.idle":"2022-09-27T04:47:08.944445Z","shell.execute_reply.started":"2022-09-27T04:46:58.692740Z","shell.execute_reply":"2022-09-27T04:47:08.943283Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (3.1.0)\nRequirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from h5py) (1.21.6)\nRequirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py) (1.5.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv('../input/mayo-clinic-strip-ai/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-09-27T04:47:08.946258Z","iopub.execute_input":"2022-09-27T04:47:08.946988Z","iopub.status.idle":"2022-09-27T04:47:08.966766Z","shell.execute_reply.started":"2022-09-27T04:47:08.946943Z","shell.execute_reply":"2022-09-27T04:47:08.965908Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df['label'] = df['label'].apply(lambda x: 1 if x == 'CE' else 0)","metadata":{"execution":{"iopub.status.busy":"2022-09-27T04:47:08.970651Z","iopub.execute_input":"2022-09-27T04:47:08.970987Z","iopub.status.idle":"2022-09-27T04:47:08.984313Z","shell.execute_reply.started":"2022-09-27T04:47:08.970958Z","shell.execute_reply":"2022-09-27T04:47:08.983202Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df = df.set_index('image_id')","metadata":{"execution":{"iopub.status.busy":"2022-09-27T04:47:08.987473Z","iopub.execute_input":"2022-09-27T04:47:08.988319Z","iopub.status.idle":"2022-09-27T04:47:08.997026Z","shell.execute_reply.started":"2022-09-27T04:47:08.988282Z","shell.execute_reply":"2022-09-27T04:47:08.995968Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"samples = pd.read_csv('../input/mayo-clinic-strip-ai/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-09-27T04:47:08.998492Z","iopub.execute_input":"2022-09-27T04:47:08.998924Z","iopub.status.idle":"2022-09-27T04:47:09.008586Z","shell.execute_reply.started":"2022-09-27T04:47:08.998889Z","shell.execute_reply":"2022-09-27T04:47:09.007563Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"final_data= pd.read_csv('../input/final-preprocessing/navigation_v2.csv')\nfinal_data = final_data.set_index('Unnamed: 0')\nfinal_data = final_data.astype(object)","metadata":{"execution":{"iopub.status.busy":"2022-09-27T04:47:09.010073Z","iopub.execute_input":"2022-09-27T04:47:09.010791Z","iopub.status.idle":"2022-09-27T04:47:10.097665Z","shell.execute_reply.started":"2022-09-27T04:47:09.010751Z","shell.execute_reply":"2022-09-27T04:47:10.096638Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3552: DtypeWarning: Columns (2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,2231,2232,2233,2234,2235,2236,2237,2238,2239,2240,2241,2242,2243,2244,2245,2246,2247,2248,2249,2250,2251,2252,2253,2254,2255,2256,2257,2258,2259,2260,2261,2262,2263,2264,2265,2266,2267,2268,2269,2270,2271,2272,2273,2274,2275,2276,2277,2278,2279,2280,2281,2282,2283,2284,2285,2286,2287,2288,2289,2290,2291,2292,2293,2294,2295,2296,2297,2298,2299,2300,2301,2302,2303,2304,2305,2306,2307,2308,2309,2310,2311,2312,2313,2314,2315,2316,2317,2318,2319,2320,2321,2322,2323,2324,2325,2326,2327,2328,2329,2330,2331,2332,2333,2334,2335,2336,2337,2338,2339,2340,2341,2342,2343,2344,2345,2346,2347,2348,2349,2350,2351,2352,2353,2354,2355,2356,2357,2358,2359,2360,2361,2362,2363,2364,2365,2366,2367,2368,2369,2370,2371,2372,2373,2374,2375,2376,2377,2378,2379,2380,2381,2382,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2393,2394,2395,2396,2397,2398,2399,2400,2401,2402,2403,2404,2405,2406,2407,2408,2409,2410,2411,2412,2413,2414,2415,2416,2417,2418,2419,2420,2421,2422,2423,2424,2425,2426,2427,2428,2429,2430,2431,2432,2433,2434,2435,2436,2437,2438,2439,2440,2441,2442,2443,2444,2445,2446,2447,2448,2449,2450,2451,2452,2453,2454,2455,2456,2457,2458,2459,2460,2461,2462,2463,2464,2465,2466,2467,2468,2469,2470,2471,2472,2473,2474,2475,2476,2477,2478,2479,2480,2481,2482,2483,2484,2485,2486,2487,2488,2489,2490,2491,2492,2493,2494,2495,2496,2497,2498,2499,2500,2501,2502,2503,2504,2505,2506,2507,2508,2509,2510,2511,2512,2513,2514,2515,2516,2517,2518,2519,2520,2521,2522,2523,2524,2525,2526,2527,2528,2529,2530,2531,2532,2533,2534,2535,2536,2537,2538,2539,2540,2541,2542,2543,2544,2545,2546,2547,2548,2549,2550,2551,2552,2553,2554,2555,2556,2557,2558,2559,2560,2561,2562,2563,2564,2565,2566,2567,2568,2569,2570,2571,2572,2573,2574,2575,2576,2577,2578,2579,2580,2581,2582,2583,2584,2585,2586,2587,2588,2589,2590,2591,2592,2593,2594,2595,2596,2597,2598,2599,2600,2601,2602,2603,2604,2605,2606,2607,2608,2609,2610,2611,2612,2613,2614,2615,2616,2617,2618,2619,2620,2621,2622,2623,2624,2625,2626,2627,2628,2629,2630,2631,2632,2633,2634,2635,2636,2637,2638,2639,2640,2641,2642,2643,2644,2645,2646,2647,2648,2649,2650,2651,2652,2653,2654,2655,2656,2657,2658,2659,2660,2661,2662,2663,2664,2665,2666,2667,2668,2669,2670,2671,2672,2673,2674,2675,2676,2677,2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2688,2689,2690,2691,2692,2693,2694,2695,2696,2697,2698,2699,2700,2701,2702,2703,2704,2705,2706,2707,2708,2709,2710,2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,2721,2722,2723,2724,2725,2726,2727,2728,2729,2730,2731,2732,2733,2734,2735,2736,2737,2738,2739,2740,2741,2742,2743,2744,2745,2746,2747,2748,2749,2750,2751,2752,2753,2754,2755,2756,2757,2758,2759,2760,2761,2762,2763,2764,2765,2766,2767,2768,2769,2770,2771) have mixed types.Specify dtype option on import or set low_memory=False.\n  exec(code_obj, self.user_global_ns, self.user_ns)\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_patch(path, tl_pixel, patch_shape):\n    img = openslide.open_slide(path)\n    img = np.array(img.read_region(tl_pixel, 0, patch_shape).convert(\"RGB\"))\n    return cv2.resize(img/255.0, (512, 512))","metadata":{"execution":{"iopub.status.busy":"2022-09-27T04:47:10.099571Z","iopub.execute_input":"2022-09-27T04:47:10.099954Z","iopub.status.idle":"2022-09-27T04:47:10.107223Z","shell.execute_reply.started":"2022-09-27T04:47:10.099917Z","shell.execute_reply":"2022-09-27T04:47:10.105768Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# def get_patch2(os_obj, tl_pixel, patch_shape):\n#     return np.array(os_obj.read_region(tl_pixel, 0, patch_shape).convert(\"RGB\"))\n\n# final_data = pd.DataFrame()\n# ids = []\n# for n in range(df.shape[0]):\n#     img_path = \"../input/mayo-clinic-strip-ai/train/\"+df.iloc[n]['image_id']+\".tif\"\n#     label = df.iloc[n]['label']\n#     i_id  = df.iloc[n]['image_id']\n#     ids.append(i_id)\n#     img  = openslide.open_slide(img_path)\n#     series = pd.Series()\n#     print(n)\n#     for i in range(img.dimensions[0]//20,img.dimensions[0]-img.dimensions[0]//20,512):\n#         for j in range(img.dimensions[0]//20,img.dimensions[0]-img.dimensions[0]//20,512):\n#             im = get_patch2(img , (i,j), (512,512) )\n#             if im.std()>15.0:\n#                 s = pd.Series(data = [(i,j)])\n#                 series = series.append(s,ignore_index=True)\n#                 series = series.reset_index()\n#                 series = series.drop(\"index\",axis=1)\n#     final_data = pd.concat([final_data , series],axis=1)\n#     final_data.columns = ids\n","metadata":{"execution":{"iopub.status.busy":"2022-09-27T04:47:10.109070Z","iopub.execute_input":"2022-09-27T04:47:10.109500Z","iopub.status.idle":"2022-09-27T04:47:10.117043Z","shell.execute_reply.started":"2022-09-27T04:47:10.109454Z","shell.execute_reply":"2022-09-27T04:47:10.115902Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"global train_test_list\ntrain_test_list = np.random.choice(np.arange(754),754)","metadata":{"execution":{"iopub.status.busy":"2022-09-27T04:47:10.121822Z","iopub.execute_input":"2022-09-27T04:47:10.122138Z","iopub.status.idle":"2022-09-27T04:47:10.128221Z","shell.execute_reply.started":"2022-09-27T04:47:10.122112Z","shell.execute_reply":"2022-09-27T04:47:10.127264Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_gen(df = df , data = final_data):\n    for i in train_test_list[:650]:\n        n_images = 2771 - final_data.iloc[i].isnull().sum()\n        if n_images <5:\n            continue\n        label = df.loc[final_data.index[i]]['label']\n        if label == 0 :\n            images_list = np.arange(n_images)\n            for x in range(3):\n                final_image_list = np.random.choice(images_list, size=(5), replace=False)\n                img1 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[0]]),(512,512))\n                img2 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[1]]),(512,512))\n                img3 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[2]]),(512,512))\n                img4 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[3]]),(512,512))\n                img5 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[4]]),(512,512))\n                yield ({'input_71':img1,'input_72':img2,'input_73':img3,'input_74':img4,'input_75':img5},label)\n        else:\n            images_list = np.arange(n_images)\n            for x in range(1):\n                final_image_list = np.random.choice(images_list, size=(5), replace=False)\n                img1 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[0]]),(512,512))\n                img2 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[1]]),(512,512))\n                img3 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[2]]),(512,512))\n                img4 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[3]]),(512,512))\n                img5 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[4]]),(512,512))\n                yield ({'input_71':img1,'input_72':img2,'input_73':img3,'input_74':img4,'input_75':img5},label)\n       \n    \n    \ndef test_gen(df = df , data = final_data):\n    for i in train_test_list[650:]:\n        n_images = 2771 - final_data.iloc[i].isnull().sum()\n        if n_images <5:\n            continue\n        label = df.loc[final_data.index[i]]['label']\n        if label == 0 :\n            images_list = np.arange(n_images)\n            final_image_list = np.random.choice(images_list, size=(5), replace=False)\n            img1 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[0]]),(512,512))\n            img2 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[1]]),(512,512))\n            img3 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[2]]),(512,512))\n            img4 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[3]]),(512,512))\n            img5 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[4]]),(512,512))\n            yield ({'input_71':img1,'input_72':img2,'input_73':img3,'input_74':img4,'input_75':img5},label)\n        else:\n            images_list = np.arange(n_images)\n            final_image_list = np.random.choice(images_list, size=(5), replace=False)\n            img1 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[0]]),(512,512))\n            img2 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[1]]),(512,512))\n            img3 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[2]]),(512,512))\n            img4 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[3]]),(512,512))\n            img5 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[4]]),(512,512))\n            yield ({'input_71':img1,'input_72':img2,'input_73':img3,'input_74':img4,'input_75':img5},label)","metadata":{"execution":{"iopub.status.busy":"2022-09-27T04:47:10.130293Z","iopub.execute_input":"2022-09-27T04:47:10.131237Z","iopub.status.idle":"2022-09-27T04:47:10.158191Z","shell.execute_reply.started":"2022-09-27T04:47:10.131199Z","shell.execute_reply":"2022-09-27T04:47:10.157140Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"dataset = tf.data.Dataset.from_generator(\n     data_gen,\n     ({'input_71':tf.float32,'input_72':tf.float32,'input_73':tf.float32,'input_74':tf.float32,'input_75':tf.float32}, tf.float32),\n    ({'input_71':tf.TensorShape([512,512,3]),'input_72':tf.TensorShape([512,512,3]),'input_73':tf.TensorShape([512,512,3]),'input_74':tf.TensorShape([512,512,3]),'input_75':tf.TensorShape([512,512,3])}, tf.TensorShape([]))\n)\ntestset = tf.data.Dataset.from_generator(\n     test_gen,\n     ({'input_71':tf.float32,'input_72':tf.float32,'input_73':tf.float32,'input_74':tf.float32,'input_75':tf.float32}, tf.float32),\n    ({'input_71':tf.TensorShape([512,512,3]),'input_72':tf.TensorShape([512,512,3]),'input_73':tf.TensorShape([512,512,3]),'input_74':tf.TensorShape([512,512,3]),'input_75':tf.TensorShape([512,512,3])}, tf.TensorShape([]))\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-27T04:47:10.159733Z","iopub.execute_input":"2022-09-27T04:47:10.160272Z","iopub.status.idle":"2022-09-27T04:47:12.786321Z","shell.execute_reply.started":"2022-09-27T04:47:10.160190Z","shell.execute_reply":"2022-09-27T04:47:12.785342Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"2022-09-27 04:47:10.225344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-27 04:47:10.313595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-27 04:47:10.314391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-27 04:47:10.317793: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-09-27 04:47:10.318348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-27 04:47:10.319526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-27 04:47:10.320787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-27 04:47:12.343748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-27 04:47:12.344683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-27 04:47:12.345393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-27 04:47:12.346109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndataset = dataset.batch(4)\ndataset = dataset.shuffle(buffer_size = 10, seed=3)\ndataset=dataset.prefetch(1)\ntestset = testset.batch(4)\ntestset=testset.prefetch(1)","metadata":{"execution":{"iopub.status.busy":"2022-09-27T04:47:12.788141Z","iopub.execute_input":"2022-09-27T04:47:12.788500Z","iopub.status.idle":"2022-09-27T04:47:12.816158Z","shell.execute_reply.started":"2022-09-27T04:47:12.788464Z","shell.execute_reply":"2022-09-27T04:47:12.815244Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"efficient = tf.keras.applications.EfficientNetB1(\n    include_top=False,\n    weights='imagenet',\n    input_shape=(512,512,3),\n)\ndef augmentation(A):\n    A = tf.keras.layers.RandomFlip()(A)\n    A =tf.keras.layers.RandomRotation(\n        (-0.2, 0.2),\n        fill_mode='reflect',\n        interpolation='bilinear',\n        seed=None,\n        fill_value=0.0,\n    )(A)\n    A = tf.keras.layers.RandomZoom(\n        (-0.1,0.1),\n        (-0.1,0.1),\n        fill_mode='reflect',\n        interpolation='bilinear',\n        seed=None,\n        fill_value=0.0,\n    )(A)\n    return A","metadata":{"execution":{"iopub.status.busy":"2022-09-27T04:47:12.817727Z","iopub.execute_input":"2022-09-27T04:47:12.818488Z","iopub.status.idle":"2022-09-27T04:47:15.827490Z","shell.execute_reply.started":"2022-09-27T04:47:12.818452Z","shell.execute_reply":"2022-09-27T04:47:15.826483Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb1_notop.h5\n27025408/27018416 [==============================] - 0s 0us/step\n27033600/27018416 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"inputA = keras.layers.Input(shape=(512,512,3),name='input_71')\ninputB = keras.layers.Input(shape=(512,512,3),name='input_72')\ninputC = keras.layers.Input(shape=(512,512,3),name='input_73')\ninputD = keras.layers.Input(shape=(512,512,3),name='input_74')\ninputE = keras.layers.Input(shape=(512,512,3),name='input_75')\n\nA = augmentation(inputA)\nA = efficient(A)\nA = keras.models.Model(inputs=inputA, outputs=A)\nB = augmentation(inputB)\nB = efficient(B)\nB = keras.models.Model(inputs=inputB, outputs=B)\nC = augmentation(inputC)\nC = efficient(C)\nC = keras.models.Model(inputs=inputC, outputs=C)\nD = efficient(inputD)\nD = keras.models.Model(inputs=inputD, outputs=D)\nE = efficient(inputE)\nE = keras.models.Model(inputs=inputE, outputs=E)\n\nX = keras.layers.Concatenate(axis=-1)([A.output, B.output, C.output, D.output, E.output])\nX = keras.layers.Conv2D(512, 4, strides = 4)(X) \nX = keras.layers.Conv2D(256, 2, strides = 2)(X)\nX = keras.layers.Flatten()(X)\nX = keras.layers.BatchNormalization()(X)\nX = keras.layers.Dense(1024 ,activation = 'relu')(X)\nX = keras.layers.Dense(512 ,activation = 'relu')(X)\nX = keras.layers.Dense(128 ,activation = 'relu')(X)\nX = keras.layers.Dense(64 ,activation = 'relu')(X)\nX = keras.layers.Dense(32 ,activation = 'relu')(X)\nX = keras.layers.Dense(16 ,activation = 'relu')(X)\nX = keras.layers.Dense(8 ,activation = 'relu')(X)\nX = keras.layers.Dense(1 ,activation = 'sigmoid')(X)\n                                               \nmodel = keras.models.Model(inputs=[A.input,B.input,C.input,D.input,E.input], outputs=X)","metadata":{"execution":{"iopub.status.busy":"2022-09-27T04:47:15.829137Z","iopub.execute_input":"2022-09-27T04:47:15.829486Z","iopub.status.idle":"2022-09-27T04:47:21.106123Z","shell.execute_reply.started":"2022-09-27T04:47:15.829453Z","shell.execute_reply":"2022-09-27T04:47:21.105163Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-09-27T04:47:21.107349Z","iopub.execute_input":"2022-09-27T04:47:21.107704Z","iopub.status.idle":"2022-09-27T04:47:21.138915Z","shell.execute_reply.started":"2022-09-27T04:47:21.107670Z","shell.execute_reply":"2022-09-27T04:47:21.137935Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Model: \"model_5\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_71 (InputLayer)           [(None, 512, 512, 3) 0                                            \n__________________________________________________________________________________________________\ninput_72 (InputLayer)           [(None, 512, 512, 3) 0                                            \n__________________________________________________________________________________________________\ninput_73 (InputLayer)           [(None, 512, 512, 3) 0                                            \n__________________________________________________________________________________________________\nrandom_flip (RandomFlip)        (None, 512, 512, 3)  0           input_71[0][0]                   \n__________________________________________________________________________________________________\nrandom_flip_1 (RandomFlip)      (None, 512, 512, 3)  0           input_72[0][0]                   \n__________________________________________________________________________________________________\nrandom_flip_2 (RandomFlip)      (None, 512, 512, 3)  0           input_73[0][0]                   \n__________________________________________________________________________________________________\nrandom_rotation (RandomRotation (None, 512, 512, 3)  0           random_flip[0][0]                \n__________________________________________________________________________________________________\nrandom_rotation_1 (RandomRotati (None, 512, 512, 3)  0           random_flip_1[0][0]              \n__________________________________________________________________________________________________\nrandom_rotation_2 (RandomRotati (None, 512, 512, 3)  0           random_flip_2[0][0]              \n__________________________________________________________________________________________________\nrandom_zoom (RandomZoom)        (None, 512, 512, 3)  0           random_rotation[0][0]            \n__________________________________________________________________________________________________\nrandom_zoom_1 (RandomZoom)      (None, 512, 512, 3)  0           random_rotation_1[0][0]          \n__________________________________________________________________________________________________\nrandom_zoom_2 (RandomZoom)      (None, 512, 512, 3)  0           random_rotation_2[0][0]          \n__________________________________________________________________________________________________\ninput_74 (InputLayer)           [(None, 512, 512, 3) 0                                            \n__________________________________________________________________________________________________\ninput_75 (InputLayer)           [(None, 512, 512, 3) 0                                            \n__________________________________________________________________________________________________\nefficientnetb1 (Functional)     (None, 16, 16, 1280) 6575239     random_zoom[0][0]                \n                                                                 random_zoom_1[0][0]              \n                                                                 random_zoom_2[0][0]              \n                                                                 input_74[0][0]                   \n                                                                 input_75[0][0]                   \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 16, 16, 6400) 0           efficientnetb1[0][0]             \n                                                                 efficientnetb1[1][0]             \n                                                                 efficientnetb1[2][0]             \n                                                                 efficientnetb1[3][0]             \n                                                                 efficientnetb1[4][0]             \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 4, 4, 512)    52429312    concatenate[0][0]                \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 2, 2, 256)    524544      conv2d[0][0]                     \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 1024)         0           conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 1024)         4096        flatten[0][0]                    \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 1024)         1049600     batch_normalization[0][0]        \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 512)          524800      dense[0][0]                      \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 128)          65664       dense_1[0][0]                    \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 64)           8256        dense_2[0][0]                    \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 32)           2080        dense_3[0][0]                    \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (None, 16)           528         dense_4[0][0]                    \n__________________________________________________________________________________________________\ndense_6 (Dense)                 (None, 8)            136         dense_5[0][0]                    \n__________________________________________________________________________________________________\ndense_7 (Dense)                 (None, 1)            9           dense_6[0][0]                    \n==================================================================================================\nTotal params: 61,184,264\nTrainable params: 61,120,161\nNon-trainable params: 64,103\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_weights(\"../input/mayo-patho/model3/model\").expect_partial()","metadata":{"execution":{"iopub.status.busy":"2022-09-27T06:30:33.253310Z","iopub.execute_input":"2022-09-27T06:30:33.253684Z","iopub.status.idle":"2022-09-27T06:30:41.093285Z","shell.execute_reply.started":"2022-09-27T06:30:33.253652Z","shell.execute_reply":"2022-09-27T06:30:41.092243Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fed490e2490>"},"metadata":{}}]},{"cell_type":"code","source":"opt = tfa.optimizers.AdamW(\n    weight_decay=1e-4,\n    learning_rate = 0.00005,\n    beta_1 = 0.9,\n    beta_2 = 0.999,\n    epsilon = 1e-07,\n    name = 'AdamW',\n)\nloss = tf.keras.losses.BinaryCrossentropy(\n    label_smoothing=0.05,\n    reduction=tf.keras.losses.Reduction.AUTO,\n    name='binary_crossentropy'\n)\nmodel.compile(optimizer=opt,\n              loss=loss,\n                metrics=[tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), tf.keras.metrics.AUC()])","metadata":{"execution":{"iopub.status.busy":"2022-09-27T06:40:52.803632Z","iopub.execute_input":"2022-09-27T06:40:52.804049Z","iopub.status.idle":"2022-09-27T06:40:52.810966Z","shell.execute_reply.started":"2022-09-27T06:40:52.804014Z","shell.execute_reply":"2022-09-27T06:40:52.809931Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"!mkdir model","metadata":{"execution":{"iopub.status.busy":"2022-09-27T05:40:09.623034Z","iopub.execute_input":"2022-09-27T05:40:09.624047Z","iopub.status.idle":"2022-09-27T05:40:10.676300Z","shell.execute_reply.started":"2022-09-27T05:40:09.624007Z","shell.execute_reply":"2022-09-27T05:40:10.674970Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"model_checkpoint_callback_LASSO = tf.keras.callbacks.ModelCheckpoint(\n    filepath = './model/model',\n    monitor=\"val_loss\",\n    save_best_only=True,\n    save_weights_only=True,\n    mode=\"auto\",\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-27T05:40:10.678506Z","iopub.execute_input":"2022-09-27T05:40:10.679134Z","iopub.status.idle":"2022-09-27T05:40:10.685757Z","shell.execute_reply.started":"2022-09-27T05:40:10.679085Z","shell.execute_reply":"2022-09-27T05:40:10.684654Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"H = model.fit(dataset, validation_data=testset, epochs=1, callbacks=[model_checkpoint_callback_LASSO])","metadata":{"execution":{"iopub.status.busy":"2022-09-27T06:55:15.720901Z","iopub.execute_input":"2022-09-27T06:55:15.721303Z","iopub.status.idle":"2022-09-27T07:06:33.337358Z","shell.execute_reply.started":"2022-09-27T06:55:15.721272Z","shell.execute_reply":"2022-09-27T07:06:33.336380Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"2022-09-27 06:56:22.893015: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 5 of 10\n2022-09-27 06:56:33.903031: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:228] Shuffle buffer filled.\n","output_type":"stream"},{"name":"stdout","text":"255/255 [==============================] - 678s 2s/step - loss: 0.6248 - recall_5: 0.5482 - precision_5: 0.7082 - auc_5: 0.6966 - val_loss: 0.6136 - val_recall_5: 0.9865 - val_precision_5: 0.7157 - val_auc_5: 0.5699\n","output_type":"stream"}]},{"cell_type":"code","source":"!mkdir final_model","metadata":{"execution":{"iopub.status.busy":"2022-09-26T04:34:53.412358Z","iopub.execute_input":"2022-09-26T04:34:53.413182Z","iopub.status.idle":"2022-09-26T04:34:54.545687Z","shell.execute_reply.started":"2022-09-26T04:34:53.413152Z","shell.execute_reply":"2022-09-26T04:34:54.544268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir best_model","metadata":{"execution":{"iopub.status.busy":"2022-09-27T06:31:01.293054Z","iopub.execute_input":"2022-09-27T06:31:01.294036Z","iopub.status.idle":"2022-09-27T06:31:02.354621Z","shell.execute_reply.started":"2022-09-27T06:31:01.294001Z","shell.execute_reply":"2022-09-27T06:31:02.353259Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"model.save('./final_model/model')","metadata":{"execution":{"iopub.status.busy":"2022-09-26T04:35:55.152169Z","iopub.execute_input":"2022-09-26T04:35:55.153306Z","iopub.status.idle":"2022-09-26T04:37:12.165410Z","shell.execute_reply.started":"2022-09-26T04:35:55.153250Z","shell.execute_reply":"2022-09-26T04:37:12.164359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('./model3/model').expect_partial()\nopt = tfa.optimizers.AdamW(\n    weight_decay=1e-4,\n    learning_rate = 0.00005,\n    beta_1 = 0.9,\n    beta_2 = 0.999,\n    epsilon = 1e-07,\n)\nloss = tf.keras.losses.BinaryCrossentropy(\n    label_smoothing=0.05,\n    reduction=tf.keras.losses.Reduction.AUTO,\n)\nmodel.compile(optimizer=opt,\n              loss=loss,\n                metrics=[tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), tf.keras.metrics.AUC()])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('./best_model/model')","metadata":{"execution":{"iopub.status.busy":"2022-09-27T07:09:01.281002Z","iopub.execute_input":"2022-09-27T07:09:01.281413Z","iopub.status.idle":"2022-09-27T07:10:22.797756Z","shell.execute_reply.started":"2022-09-27T07:09:01.281381Z","shell.execute_reply":"2022-09-27T07:10:22.796748Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n  category=CustomMaskWarning)\n","output_type":"stream"}]},{"cell_type":"code","source":"model.evaluate(testset)","metadata":{"execution":{"iopub.status.busy":"2022-09-27T06:32:58.761957Z","iopub.execute_input":"2022-09-27T06:32:58.762342Z","iopub.status.idle":"2022-09-27T06:34:02.873463Z","shell.execute_reply.started":"2022-09-27T06:32:58.762307Z","shell.execute_reply":"2022-09-27T06:34:02.872246Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"26/26 [==============================] - 64s 2s/step - loss: 0.6066 - recall_1: 1.0000 - precision_1: 0.7184 - auc_1: 0.5582\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"[0.6066494584083557, 1.0, 0.7184466123580933, 0.5582479238510132]"},"metadata":{}}]},{"cell_type":"code","source":"# def get_patch1(img, tl_pixel, patch_shape):\n#     img = np.array(img.read_region(tl_pixel, 0, patch_shape).convert(\"RGB\"))\n#     return img\n\n# final_samples= pd.DataFrame()\n# ids = []\n# for n in tqdm(range(samples.shape[0])):\n#     img_path = \"../input/mayo-clinic-strip-ai/test/\"+samples.iloc[n]['image_id']+\".tif\"\n#    #label = samples.iloc[n]['label']\n#     i_id = samples.iloc[n]['image_id']\n#     ids.append(i_id)\n#     img  = openslide.open_slide(img_path)\n#     series = pd.Series()\n#     n = 0\n#     for i in range(img.dimensions[0]//20,img.dimensions[0]-img.dimensions[0]//20,512):\n#         for j in range(img.dimensions[0]//20,img.dimensions[0]-img.dimensions[0]//20,512):\n#             if n ==20:\n#                 break           \n#             im = get_patch1(img , (i,j), (512,512) )\n#             if im.std()>10.0:\n#                 n=n+1\n#                 s = pd.Series(data = [(i,j)])\n#                 series = series.append(s,ignore_index=True)\n#                 series = series.reset_index()\n#                 series = series.drop(\"index\",axis=1)\n#     final_samples = pd.concat([final_samples , series],axis=1)\n#     final_samples.columns = ids\n# final_samples = final_samples.T\n","metadata":{"execution":{"iopub.status.busy":"2022-09-25T19:24:23.311169Z","iopub.status.idle":"2022-09-25T19:24:23.312001Z","shell.execute_reply.started":"2022-09-25T19:24:23.311736Z","shell.execute_reply":"2022-09-25T19:24:23.311764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final_samples","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# samples","metadata":{"execution":{"iopub.status.busy":"2022-09-04T04:35:34.954268Z","iopub.execute_input":"2022-09-04T04:35:34.955190Z","iopub.status.idle":"2022-09-04T04:35:34.984954Z","shell.execute_reply.started":"2022-09-04T04:35:34.955134Z","shell.execute_reply":"2022-09-04T04:35:34.983615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def sample_gen(df = samples , data = final_samples):\n#     for i in range(samples.shape[0]):\n#         img1 = get_patch('../input/mayo-clinic-strip-ai/test/'+df.iloc[i]['image_id']+'.tif' , (data.loc[df.iloc[i]['image_id']][0]),(512,512))\n#         img2 = get_patch('../input/mayo-clinic-strip-ai/test/'+df.iloc[i]['image_id']+'.tif' , (data.loc[df.iloc[i]['image_id']][1]),(512,512))\n#         img3 = get_patch('../input/mayo-clinic-strip-ai/test/'+df.iloc[i]['image_id']+'.tif' , (data.loc[df.iloc[i]['image_id']][2]),(512,512))\n#         img4 = get_patch('../input/mayo-clinic-strip-ai/test/'+df.iloc[i]['image_id']+'.tif' , (data.loc[df.iloc[i]['image_id']][3]),(512,512))\n#         img5 = get_patch('../input/mayo-clinic-strip-ai/test/'+df.iloc[i]['image_id']+'.tif' , (data.loc[df.iloc[i]['image_id']][4]),(512,512))\n#         yield ({'input_71':img1,'input_72':img2,'input_73':img3,'input_74':img4,'input_75':img5})\n# sampleset = tf.data.Dataset.from_generator(\n#      sample_gen,\n#      ({'input_71':tf.float32,'input_72':tf.float32,'input_73':tf.float32,'input_74':tf.float32,'input_75':tf.float32}),\n#     ({'input_71':tf.TensorShape([512,512,3]),'input_72':tf.TensorShape([512,512,3]),'input_73':tf.TensorShape([512,512,3]),'input_74':tf.TensorShape([512,512,3]),'input_75':tf.TensorShape([512,512,3])}))\n","metadata":{"execution":{"iopub.status.busy":"2022-09-04T04:36:45.212957Z","iopub.execute_input":"2022-09-04T04:36:45.213417Z","iopub.status.idle":"2022-09-04T04:36:45.256234Z","shell.execute_reply.started":"2022-09-04T04:36:45.213386Z","shell.execute_reply":"2022-09-04T04:36:45.254885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# weight_file = \"./model\"\n# model.load_weights(weight_file).expect_partial()\n# print(\"Weights loaded successfully\")","metadata":{"execution":{"iopub.status.busy":"2022-09-04T04:36:45.377993Z","iopub.execute_input":"2022-09-04T04:36:45.379009Z","iopub.status.idle":"2022-09-04T04:36:47.296697Z","shell.execute_reply.started":"2022-09-04T04:36:45.378965Z","shell.execute_reply":"2022-09-04T04:36:47.295164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# weight_file = \"./model\"\n# model.load_weights(weight_file).expect_partial()\n# print(\"Weights loaded successfully\")","metadata":{"execution":{"iopub.status.busy":"2022-09-04T04:36:45.377993Z","iopub.execute_input":"2022-09-04T04:36:45.379009Z","iopub.status.idle":"2022-09-04T04:36:47.296697Z","shell.execute_reply.started":"2022-09-04T04:36:45.378965Z","shell.execute_reply":"2022-09-04T04:36:47.295164Z"},"trusted":true},"execution_count":null,"outputs":[]}]}