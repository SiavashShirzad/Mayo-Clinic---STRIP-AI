{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import openslide\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport cv2\nimport ast\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow_addons as tfa","metadata":{"execution":{"iopub.status.busy":"2022-09-22T16:19:49.111954Z","iopub.execute_input":"2022-09-22T16:19:49.112994Z","iopub.status.idle":"2022-09-22T16:19:55.643208Z","shell.execute_reply.started":"2022-09-22T16:19:49.112829Z","shell.execute_reply":"2022-09-22T16:19:55.642257Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/mayo-clinic-strip-ai/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-09-22T16:19:55.645196Z","iopub.execute_input":"2022-09-22T16:19:55.645791Z","iopub.status.idle":"2022-09-22T16:19:55.664676Z","shell.execute_reply.started":"2022-09-22T16:19:55.645761Z","shell.execute_reply":"2022-09-22T16:19:55.663726Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df['label'] = df['label'].apply(lambda x: 1 if x == 'CE' else 0)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T16:19:55.667829Z","iopub.execute_input":"2022-09-22T16:19:55.669022Z","iopub.status.idle":"2022-09-22T16:19:55.679614Z","shell.execute_reply.started":"2022-09-22T16:19:55.668984Z","shell.execute_reply":"2022-09-22T16:19:55.678595Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = df.set_index('image_id')","metadata":{"execution":{"iopub.status.busy":"2022-09-22T16:19:55.682659Z","iopub.execute_input":"2022-09-22T16:19:55.683081Z","iopub.status.idle":"2022-09-22T16:19:55.693625Z","shell.execute_reply.started":"2022-09-22T16:19:55.683045Z","shell.execute_reply":"2022-09-22T16:19:55.692604Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"samples = pd.read_csv('../input/mayo-clinic-strip-ai/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-09-22T16:19:55.695344Z","iopub.execute_input":"2022-09-22T16:19:55.695727Z","iopub.status.idle":"2022-09-22T16:19:55.708336Z","shell.execute_reply.started":"2022-09-22T16:19:55.695653Z","shell.execute_reply":"2022-09-22T16:19:55.707442Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"final_data= pd.read_csv('../input/final-preprocessing/navigation_v2.csv')\nfinal_data = final_data.set_index('Unnamed: 0')\nfinal_data = final_data.astype(object)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T16:19:55.709977Z","iopub.execute_input":"2022-09-22T16:19:55.710444Z","iopub.status.idle":"2022-09-22T16:19:56.564360Z","shell.execute_reply.started":"2022-09-22T16:19:55.710401Z","shell.execute_reply":"2022-09-22T16:19:56.563403Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3552: DtypeWarning: Columns (2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,2231,2232,2233,2234,2235,2236,2237,2238,2239,2240,2241,2242,2243,2244,2245,2246,2247,2248,2249,2250,2251,2252,2253,2254,2255,2256,2257,2258,2259,2260,2261,2262,2263,2264,2265,2266,2267,2268,2269,2270,2271,2272,2273,2274,2275,2276,2277,2278,2279,2280,2281,2282,2283,2284,2285,2286,2287,2288,2289,2290,2291,2292,2293,2294,2295,2296,2297,2298,2299,2300,2301,2302,2303,2304,2305,2306,2307,2308,2309,2310,2311,2312,2313,2314,2315,2316,2317,2318,2319,2320,2321,2322,2323,2324,2325,2326,2327,2328,2329,2330,2331,2332,2333,2334,2335,2336,2337,2338,2339,2340,2341,2342,2343,2344,2345,2346,2347,2348,2349,2350,2351,2352,2353,2354,2355,2356,2357,2358,2359,2360,2361,2362,2363,2364,2365,2366,2367,2368,2369,2370,2371,2372,2373,2374,2375,2376,2377,2378,2379,2380,2381,2382,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2393,2394,2395,2396,2397,2398,2399,2400,2401,2402,2403,2404,2405,2406,2407,2408,2409,2410,2411,2412,2413,2414,2415,2416,2417,2418,2419,2420,2421,2422,2423,2424,2425,2426,2427,2428,2429,2430,2431,2432,2433,2434,2435,2436,2437,2438,2439,2440,2441,2442,2443,2444,2445,2446,2447,2448,2449,2450,2451,2452,2453,2454,2455,2456,2457,2458,2459,2460,2461,2462,2463,2464,2465,2466,2467,2468,2469,2470,2471,2472,2473,2474,2475,2476,2477,2478,2479,2480,2481,2482,2483,2484,2485,2486,2487,2488,2489,2490,2491,2492,2493,2494,2495,2496,2497,2498,2499,2500,2501,2502,2503,2504,2505,2506,2507,2508,2509,2510,2511,2512,2513,2514,2515,2516,2517,2518,2519,2520,2521,2522,2523,2524,2525,2526,2527,2528,2529,2530,2531,2532,2533,2534,2535,2536,2537,2538,2539,2540,2541,2542,2543,2544,2545,2546,2547,2548,2549,2550,2551,2552,2553,2554,2555,2556,2557,2558,2559,2560,2561,2562,2563,2564,2565,2566,2567,2568,2569,2570,2571,2572,2573,2574,2575,2576,2577,2578,2579,2580,2581,2582,2583,2584,2585,2586,2587,2588,2589,2590,2591,2592,2593,2594,2595,2596,2597,2598,2599,2600,2601,2602,2603,2604,2605,2606,2607,2608,2609,2610,2611,2612,2613,2614,2615,2616,2617,2618,2619,2620,2621,2622,2623,2624,2625,2626,2627,2628,2629,2630,2631,2632,2633,2634,2635,2636,2637,2638,2639,2640,2641,2642,2643,2644,2645,2646,2647,2648,2649,2650,2651,2652,2653,2654,2655,2656,2657,2658,2659,2660,2661,2662,2663,2664,2665,2666,2667,2668,2669,2670,2671,2672,2673,2674,2675,2676,2677,2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2688,2689,2690,2691,2692,2693,2694,2695,2696,2697,2698,2699,2700,2701,2702,2703,2704,2705,2706,2707,2708,2709,2710,2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,2721,2722,2723,2724,2725,2726,2727,2728,2729,2730,2731,2732,2733,2734,2735,2736,2737,2738,2739,2740,2741,2742,2743,2744,2745,2746,2747,2748,2749,2750,2751,2752,2753,2754,2755,2756,2757,2758,2759,2760,2761,2762,2763,2764,2765,2766,2767,2768,2769,2770,2771) have mixed types.Specify dtype option on import or set low_memory=False.\n  exec(code_obj, self.user_global_ns, self.user_ns)\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_patch(path, tl_pixel, patch_shape):\n    img = openslide.open_slide(path)\n    img = np.array(img.read_region(tl_pixel, 0, patch_shape).convert(\"RGB\"))\n    return cv2.resize(img/255.0, (512, 512))","metadata":{"execution":{"iopub.status.busy":"2022-09-22T16:19:56.565955Z","iopub.execute_input":"2022-09-22T16:19:56.566414Z","iopub.status.idle":"2022-09-22T16:19:56.572364Z","shell.execute_reply.started":"2022-09-22T16:19:56.566378Z","shell.execute_reply":"2022-09-22T16:19:56.571203Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# def get_patch2(os_obj, tl_pixel, patch_shape):\n#     return np.array(os_obj.read_region(tl_pixel, 0, patch_shape).convert(\"RGB\"))\n\n# final_data = pd.DataFrame()\n# ids = []\n# for n in range(df.shape[0]):\n#     img_path = \"../input/mayo-clinic-strip-ai/train/\"+df.iloc[n]['image_id']+\".tif\"\n#     label = df.iloc[n]['label']\n#     i_id  = df.iloc[n]['image_id']\n#     ids.append(i_id)\n#     img  = openslide.open_slide(img_path)\n#     series = pd.Series()\n#     print(n)\n#     for i in range(img.dimensions[0]//20,img.dimensions[0]-img.dimensions[0]//20,512):\n#         for j in range(img.dimensions[0]//20,img.dimensions[0]-img.dimensions[0]//20,512):\n#             im = get_patch2(img , (i,j), (512,512) )\n#             if im.std()>15.0:\n#                 s = pd.Series(data = [(i,j)])\n#                 series = series.append(s,ignore_index=True)\n#                 series = series.reset_index()\n#                 series = series.drop(\"index\",axis=1)\n#     final_data = pd.concat([final_data , series],axis=1)\n#     final_data.columns = ids\n","metadata":{"execution":{"iopub.status.busy":"2022-09-22T16:19:56.574209Z","iopub.execute_input":"2022-09-22T16:19:56.574965Z","iopub.status.idle":"2022-09-22T16:19:56.582619Z","shell.execute_reply.started":"2022-09-22T16:19:56.574919Z","shell.execute_reply":"2022-09-22T16:19:56.581654Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def data_gen(df = df , data = final_data):\n    for i in range(0,650):\n        n_images = 2771 - final_data.iloc[i].isnull().sum()\n        if n_images <5:\n            continue\n        label = df.loc[final_data.index[i]]['label']\n        if label == 0 :\n            images_list = np.arange(n_images)\n            for x in range(3):\n                final_image_list = np.random.choice(images_list, size=(5), replace=False)\n                img1 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[0]]),(512,512))\n                img2 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[1]]),(512,512))\n                img3 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[2]]),(512,512))\n                img4 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[3]]),(512,512))\n                img5 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[4]]),(512,512))\n                yield ({'input_71':img1,'input_72':img2,'input_73':img3,'input_74':img4,'input_75':img5},label)\n        else:\n            images_list = np.arange(n_images)\n            for x in range(1):\n                final_image_list = np.random.choice(images_list, size=(5), replace=False)\n                img1 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[0]]),(512,512))\n                img2 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[1]]),(512,512))\n                img3 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[2]]),(512,512))\n                img4 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[3]]),(512,512))\n                img5 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[4]]),(512,512))\n                yield ({'input_71':img1,'input_72':img2,'input_73':img3,'input_74':img4,'input_75':img5},label)\n       \n    \n    \ndef test_gen(df = df , data = final_data):\n    for i in range(650,754):\n        n_images = 2771 - final_data.iloc[i].isnull().sum()\n        if n_images <5:\n            continue\n        label = df.loc[final_data.index[i]]['label']\n        if label == 0 :\n            images_list = np.arange(n_images)\n            final_image_list = np.random.choice(images_list, size=(5), replace=False)\n            img1 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[0]]),(512,512))\n            img2 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[1]]),(512,512))\n            img3 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[2]]),(512,512))\n            img4 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[3]]),(512,512))\n            img5 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[4]]),(512,512))\n            yield ({'input_71':img1,'input_72':img2,'input_73':img3,'input_74':img4,'input_75':img5},label)\n        else:\n            images_list = np.arange(n_images)\n            final_image_list = np.random.choice(images_list, size=(5), replace=False)\n            img1 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[0]]),(512,512))\n            img2 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[1]]),(512,512))\n            img3 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[2]]),(512,512))\n            img4 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[3]]),(512,512))\n            img5 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[4]]),(512,512))\n            yield ({'input_71':img1,'input_72':img2,'input_73':img3,'input_74':img4,'input_75':img5},label)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T16:19:56.585655Z","iopub.execute_input":"2022-09-22T16:19:56.585996Z","iopub.status.idle":"2022-09-22T16:19:56.611365Z","shell.execute_reply.started":"2022-09-22T16:19:56.585970Z","shell.execute_reply":"2022-09-22T16:19:56.610472Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"dataset = tf.data.Dataset.from_generator(\n     data_gen,\n     ({'input_71':tf.float32,'input_72':tf.float32,'input_73':tf.float32,'input_74':tf.float32,'input_75':tf.float32}, tf.float32),\n    ({'input_71':tf.TensorShape([512,512,3]),'input_72':tf.TensorShape([512,512,3]),'input_73':tf.TensorShape([512,512,3]),'input_74':tf.TensorShape([512,512,3]),'input_75':tf.TensorShape([512,512,3])}, tf.TensorShape([]))\n)\ntestset = tf.data.Dataset.from_generator(\n     test_gen,\n     ({'input_71':tf.float32,'input_72':tf.float32,'input_73':tf.float32,'input_74':tf.float32,'input_75':tf.float32}, tf.float32),\n    ({'input_71':tf.TensorShape([512,512,3]),'input_72':tf.TensorShape([512,512,3]),'input_73':tf.TensorShape([512,512,3]),'input_74':tf.TensorShape([512,512,3]),'input_75':tf.TensorShape([512,512,3])}, tf.TensorShape([]))\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T16:19:56.614862Z","iopub.execute_input":"2022-09-22T16:19:56.615330Z","iopub.status.idle":"2022-09-22T16:19:59.726481Z","shell.execute_reply.started":"2022-09-22T16:19:56.615292Z","shell.execute_reply":"2022-09-22T16:19:59.725482Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"2022-09-22 16:19:56.694997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-22 16:19:56.800991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-22 16:19:56.801766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-22 16:19:56.804789: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-09-22 16:19:56.805116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-22 16:19:56.805939: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-22 16:19:56.806667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-22 16:19:59.282803: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-22 16:19:59.283672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-22 16:19:59.284377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-22 16:19:59.285000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndataset = dataset.batch(2)\ndataset=dataset.prefetch(1)\ndataset = dataset.shuffle(buffer_size = 10, seed=3)\ntestset = testset.batch(2)\ntestset=testset.prefetch(1)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T16:19:59.729297Z","iopub.execute_input":"2022-09-22T16:19:59.729589Z","iopub.status.idle":"2022-09-22T16:19:59.758068Z","shell.execute_reply.started":"2022-09-22T16:19:59.729562Z","shell.execute_reply":"2022-09-22T16:19:59.757251Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"efficient = tf.keras.applications.EfficientNetB4(\n    include_top=False,\n    weights='imagenet',\n    input_tensor=None,\n    input_shape=(512,512,3),\n    pooling=None,\n)\ndef augmentation(A):\n    A = tf.keras.layers.RandomFlip()(A)\n    A =tf.keras.layers.RandomRotation(\n        (-0.2, 0.2),\n        fill_mode='reflect',\n        interpolation='bilinear',\n        seed=None,\n        fill_value=0.0,\n    )(A)\n    A = tf.keras.layers.RandomZoom(\n        (-0.1,0.1),\n        (-0.1,0.1),\n        fill_mode='reflect',\n        interpolation='bilinear',\n        seed=None,\n        fill_value=0.0,\n    )(A)\n    return A","metadata":{"execution":{"iopub.status.busy":"2022-09-22T16:19:59.759526Z","iopub.execute_input":"2022-09-22T16:19:59.760172Z","iopub.status.idle":"2022-09-22T16:20:03.243720Z","shell.execute_reply.started":"2022-09-22T16:19:59.760135Z","shell.execute_reply":"2022-09-22T16:20:03.242686Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n71688192/71686520 [==============================] - 0s 0us/step\n71696384/71686520 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"inputA = keras.layers.Input(shape=(512,512,3),name='input_71')\ninputB = keras.layers.Input(shape=(512,512,3),name='input_72')\ninputC = keras.layers.Input(shape=(512,512,3),name='input_73')\ninputD = keras.layers.Input(shape=(512,512,3),name='input_74')\ninputE = keras.layers.Input(shape=(512,512,3),name='input_75')\n\nA = augmentation(inputA)\nA = efficient(A)\nA = keras.models.Model(inputs=inputA, outputs=A)\nB = augmentation(inputB)\nB = efficient(B)\nB = keras.models.Model(inputs=inputB, outputs=B)\nC = augmentation(inputC)\nC = efficient(C)\nC = keras.models.Model(inputs=inputC, outputs=C)\nD = efficient(inputD)\nD = keras.models.Model(inputs=inputD, outputs=D)\nE = efficient(inputE)\nE = keras.models.Model(inputs=inputE, outputs=E)\n\nX = keras.layers.Concatenate(axis=-1)([A.output, B.output, C.output, D.output, E.output])\nX = keras.layers.Conv2D(128, 3, padding=\"same\")(X) \nX = keras.layers.Conv2D(32, 3, padding=\"same\")(X)\nX = keras.layers.Conv2D(16, 3, padding=\"same\")(X)\nX = keras.layers.Flatten()(X)\nX = keras.layers.BatchNormalization()(X)\n\nX = keras.layers.Dense(64 ,activation = 'relu')(X)\nX = keras.layers.Dense(32 ,activation = 'relu')(X)\nX = keras.layers.Dense(16 ,activation = 'relu')(X)\nX = keras.layers.Dense(8 ,activation = 'relu')(X)\nX = keras.layers.Dense(1 ,activation = 'sigmoid')(X)\n                                               \nmodel = keras.models.Model(inputs=[A.input,B.input,C.input,D.input,E.input], outputs=X)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T16:32:35.218758Z","iopub.execute_input":"2022-09-22T16:32:35.219502Z","iopub.status.idle":"2022-09-22T16:32:42.003443Z","shell.execute_reply.started":"2022-09-22T16:32:35.219463Z","shell.execute_reply":"2022-09-22T16:32:42.002482Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-09-22T16:32:42.005336Z","iopub.execute_input":"2022-09-22T16:32:42.005739Z","iopub.status.idle":"2022-09-22T16:32:42.036487Z","shell.execute_reply.started":"2022-09-22T16:32:42.005703Z","shell.execute_reply":"2022-09-22T16:32:42.035516Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Model: \"model_11\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_71 (InputLayer)           [(None, 512, 512, 3) 0                                            \n__________________________________________________________________________________________________\ninput_72 (InputLayer)           [(None, 512, 512, 3) 0                                            \n__________________________________________________________________________________________________\ninput_73 (InputLayer)           [(None, 512, 512, 3) 0                                            \n__________________________________________________________________________________________________\nrandom_flip_3 (RandomFlip)      (None, 512, 512, 3)  0           input_71[0][0]                   \n__________________________________________________________________________________________________\nrandom_flip_4 (RandomFlip)      (None, 512, 512, 3)  0           input_72[0][0]                   \n__________________________________________________________________________________________________\nrandom_flip_5 (RandomFlip)      (None, 512, 512, 3)  0           input_73[0][0]                   \n__________________________________________________________________________________________________\nrandom_rotation_3 (RandomRotati (None, 512, 512, 3)  0           random_flip_3[0][0]              \n__________________________________________________________________________________________________\nrandom_rotation_4 (RandomRotati (None, 512, 512, 3)  0           random_flip_4[0][0]              \n__________________________________________________________________________________________________\nrandom_rotation_5 (RandomRotati (None, 512, 512, 3)  0           random_flip_5[0][0]              \n__________________________________________________________________________________________________\nrandom_zoom_3 (RandomZoom)      (None, 512, 512, 3)  0           random_rotation_3[0][0]          \n__________________________________________________________________________________________________\nrandom_zoom_4 (RandomZoom)      (None, 512, 512, 3)  0           random_rotation_4[0][0]          \n__________________________________________________________________________________________________\nrandom_zoom_5 (RandomZoom)      (None, 512, 512, 3)  0           random_rotation_5[0][0]          \n__________________________________________________________________________________________________\ninput_74 (InputLayer)           [(None, 512, 512, 3) 0                                            \n__________________________________________________________________________________________________\ninput_75 (InputLayer)           [(None, 512, 512, 3) 0                                            \n__________________________________________________________________________________________________\nefficientnetb4 (Functional)     (None, 16, 16, 1792) 17673823    random_zoom_3[0][0]              \n                                                                 random_zoom_4[0][0]              \n                                                                 random_zoom_5[0][0]              \n                                                                 input_74[0][0]                   \n                                                                 input_75[0][0]                   \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 16, 16, 8960) 0           efficientnetb4[5][0]             \n                                                                 efficientnetb4[6][0]             \n                                                                 efficientnetb4[7][0]             \n                                                                 efficientnetb4[8][0]             \n                                                                 efficientnetb4[9][0]             \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 16, 16, 128)  10322048    concatenate_1[0][0]              \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 16, 16, 32)   36896       conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 16, 16, 16)   4624        conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nflatten_1 (Flatten)             (None, 4096)         0           conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 4096)         16384       flatten_1[0][0]                  \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (None, 64)           262208      batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\ndense_6 (Dense)                 (None, 32)           2080        dense_5[0][0]                    \n__________________________________________________________________________________________________\ndense_7 (Dense)                 (None, 16)           528         dense_6[0][0]                    \n__________________________________________________________________________________________________\ndense_8 (Dense)                 (None, 8)            136         dense_7[0][0]                    \n__________________________________________________________________________________________________\ndense_9 (Dense)                 (None, 1)            9           dense_8[0][0]                    \n==================================================================================================\nTotal params: 28,318,736\nTrainable params: 28,185,337\nNon-trainable params: 133,399\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"opt = tfa.optimizers.AdamW(\n    weight_decay=1e-4,\n    learning_rate = 0.00002,\n    beta_1 = 0.9,\n    beta_2 = 0.999,\n    epsilon = 1e-07,\n    name = 'AdamW',\n)\nloss = tf.keras.losses.BinaryCrossentropy(\n    reduction=tf.keras.losses.Reduction.AUTO,\n    name='binary_crossentropy'\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-23T02:02:24.556104Z","iopub.execute_input":"2022-09-23T02:02:24.556761Z","iopub.status.idle":"2022-09-23T02:02:24.564167Z","shell.execute_reply.started":"2022-09-23T02:02:24.556726Z","shell.execute_reply":"2022-09-23T02:02:24.562121Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=opt,\n              loss=loss,\n                metrics=[tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), tf.keras.metrics.AUC()])","metadata":{"execution":{"iopub.status.busy":"2022-09-23T02:02:25.652671Z","iopub.execute_input":"2022-09-23T02:02:25.653647Z","iopub.status.idle":"2022-09-23T02:02:25.727448Z","shell.execute_reply.started":"2022-09-23T02:02:25.653607Z","shell.execute_reply":"2022-09-23T02:02:25.726462Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"!mkdir model2","metadata":{"execution":{"iopub.status.busy":"2022-09-23T02:02:26.064214Z","iopub.execute_input":"2022-09-23T02:02:26.065009Z","iopub.status.idle":"2022-09-23T02:02:27.303390Z","shell.execute_reply.started":"2022-09-23T02:02:26.064953Z","shell.execute_reply":"2022-09-23T02:02:27.302122Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory ‘model2’: File exists\n","output_type":"stream"}]},{"cell_type":"code","source":"model_checkpoint_callback_LASSO = tf.keras.callbacks.ModelCheckpoint(\n    filepath = './model2/model',\n    monitor=\"val_loss\",\n    save_best_only=True,\n    save_weights_only=True,\n    mode=\"auto\",\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-23T02:02:37.944239Z","iopub.execute_input":"2022-09-23T02:02:37.944652Z","iopub.status.idle":"2022-09-23T02:02:37.951954Z","shell.execute_reply.started":"2022-09-23T02:02:37.944615Z","shell.execute_reply":"2022-09-23T02:02:37.950038Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"H = model.fit(dataset, validation_data=testset, epochs=10, callbacks=[model_checkpoint_callback_LASSO])","metadata":{"execution":{"iopub.status.busy":"2022-09-23T02:02:46.257073Z","iopub.execute_input":"2022-09-23T02:02:46.257445Z","iopub.status.idle":"2022-09-23T02:51:58.513980Z","shell.execute_reply.started":"2022-09-23T02:02:46.257412Z","shell.execute_reply":"2022-09-23T02:51:58.509696Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"2022-09-23 02:04:34.042631: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 9 of 10\n2022-09-23 02:04:35.151267: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:228] Shuffle buffer filled.\n","output_type":"stream"},{"name":"stdout","text":"497/497 [==============================] - 853s 1s/step - loss: 0.6889 - recall_2: 0.4359 - precision_2: 0.5244 - auc_1: 0.5515 - val_loss: 0.6903 - val_recall_2: 0.7123 - val_precision_2: 0.7027 - val_auc_1: 0.5021\nEpoch 2/10\n","output_type":"stream"},{"name":"stderr","text":"2022-09-23 02:17:11.613734: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 9 of 10\n2022-09-23 02:17:12.692366: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:228] Shuffle buffer filled.\n","output_type":"stream"},{"name":"stdout","text":"497/497 [==============================] - 724s 1s/step - loss: 0.6898 - recall_2: 0.3419 - precision_2: 0.5405 - auc_1: 0.5456 - val_loss: 0.7005 - val_recall_2: 0.5753 - val_precision_2: 0.7000 - val_auc_1: 0.4502\nEpoch 3/10\n","output_type":"stream"},{"name":"stderr","text":"2022-09-23 02:29:14.804346: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 5 of 10\n2022-09-23 02:29:25.482882: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:228] Shuffle buffer filled.\n","output_type":"stream"},{"name":"stdout","text":"497/497 [==============================] - 806s 2s/step - loss: 0.6876 - recall_2: 0.1880 - precision_2: 0.5752 - auc_1: 0.5947 - val_loss: 0.6884 - val_recall_2: 0.7808 - val_precision_2: 0.7308 - val_auc_1: 0.4728\nEpoch 4/10\n","output_type":"stream"},{"name":"stderr","text":"2022-09-23 02:43:36.848146: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 9 of 10\n2022-09-23 02:43:38.078414: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:228] Shuffle buffer filled.\n","output_type":"stream"},{"name":"stdout","text":"358/497 [====================>.........] - ETA: 3:14 - loss: 0.6901 - recall_2: 0.1391 - precision_2: 0.5647 - auc_1: 0.5667","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/36499775.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint_callback_LASSO\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# def get_patch1(img, tl_pixel, patch_shape):\n#     img = np.array(img.read_region(tl_pixel, 0, patch_shape).convert(\"RGB\"))\n#     return img\n\n# final_samples= pd.DataFrame()\n# ids = []\n# for n in tqdm(range(samples.shape[0])):\n#     img_path = \"../input/mayo-clinic-strip-ai/test/\"+samples.iloc[n]['image_id']+\".tif\"\n#    #label = samples.iloc[n]['label']\n#     i_id = samples.iloc[n]['image_id']\n#     ids.append(i_id)\n#     img  = openslide.open_slide(img_path)\n#     series = pd.Series()\n#     n = 0\n#     for i in range(img.dimensions[0]//20,img.dimensions[0]-img.dimensions[0]//20,512):\n#         for j in range(img.dimensions[0]//20,img.dimensions[0]-img.dimensions[0]//20,512):\n#             if n ==20:\n#                 break           \n#             im = get_patch1(img , (i,j), (512,512) )\n#             if im.std()>10.0:\n#                 n=n+1\n#                 s = pd.Series(data = [(i,j)])\n#                 series = series.append(s,ignore_index=True)\n#                 series = series.reset_index()\n#                 series = series.drop(\"index\",axis=1)\n#     final_samples = pd.concat([final_samples , series],axis=1)\n#     final_samples.columns = ids\n# final_samples = final_samples.T\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final_samples","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# samples","metadata":{"execution":{"iopub.status.busy":"2022-09-04T04:35:34.954268Z","iopub.execute_input":"2022-09-04T04:35:34.955190Z","iopub.status.idle":"2022-09-04T04:35:34.984954Z","shell.execute_reply.started":"2022-09-04T04:35:34.955134Z","shell.execute_reply":"2022-09-04T04:35:34.983615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def sample_gen(df = samples , data = final_samples):\n#     for i in range(samples.shape[0]):\n#         img1 = get_patch('../input/mayo-clinic-strip-ai/test/'+df.iloc[i]['image_id']+'.tif' , (data.loc[df.iloc[i]['image_id']][0]),(512,512))\n#         img2 = get_patch('../input/mayo-clinic-strip-ai/test/'+df.iloc[i]['image_id']+'.tif' , (data.loc[df.iloc[i]['image_id']][1]),(512,512))\n#         img3 = get_patch('../input/mayo-clinic-strip-ai/test/'+df.iloc[i]['image_id']+'.tif' , (data.loc[df.iloc[i]['image_id']][2]),(512,512))\n#         img4 = get_patch('../input/mayo-clinic-strip-ai/test/'+df.iloc[i]['image_id']+'.tif' , (data.loc[df.iloc[i]['image_id']][3]),(512,512))\n#         img5 = get_patch('../input/mayo-clinic-strip-ai/test/'+df.iloc[i]['image_id']+'.tif' , (data.loc[df.iloc[i]['image_id']][4]),(512,512))\n#         yield ({'input_71':img1,'input_72':img2,'input_73':img3,'input_74':img4,'input_75':img5})\n# sampleset = tf.data.Dataset.from_generator(\n#      sample_gen,\n#      ({'input_71':tf.float32,'input_72':tf.float32,'input_73':tf.float32,'input_74':tf.float32,'input_75':tf.float32}),\n#     ({'input_71':tf.TensorShape([512,512,3]),'input_72':tf.TensorShape([512,512,3]),'input_73':tf.TensorShape([512,512,3]),'input_74':tf.TensorShape([512,512,3]),'input_75':tf.TensorShape([512,512,3])}))\n","metadata":{"execution":{"iopub.status.busy":"2022-09-04T04:36:45.212957Z","iopub.execute_input":"2022-09-04T04:36:45.213417Z","iopub.status.idle":"2022-09-04T04:36:45.256234Z","shell.execute_reply.started":"2022-09-04T04:36:45.213386Z","shell.execute_reply":"2022-09-04T04:36:45.254885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# weight_file = \"./model\"\n# model.load_weights(weight_file).expect_partial()\n# print(\"Weights loaded successfully\")","metadata":{"execution":{"iopub.status.busy":"2022-09-04T04:36:45.377993Z","iopub.execute_input":"2022-09-04T04:36:45.379009Z","iopub.status.idle":"2022-09-04T04:36:47.296697Z","shell.execute_reply.started":"2022-09-04T04:36:45.378965Z","shell.execute_reply":"2022-09-04T04:36:47.295164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sampleset = sampleset.batch(1)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T04:36:47.298978Z","iopub.execute_input":"2022-09-04T04:36:47.299321Z","iopub.status.idle":"2022-09-04T04:36:47.310594Z","shell.execute_reply.started":"2022-09-04T04:36:47.299291Z","shell.execute_reply":"2022-09-04T04:36:47.305924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pred = model.predict(sampleset)\n# pred","metadata":{"execution":{"iopub.status.busy":"2022-09-04T04:36:47.779426Z","iopub.execute_input":"2022-09-04T04:36:47.780587Z","iopub.status.idle":"2022-09-04T04:36:57.509453Z","shell.execute_reply.started":"2022-09-04T04:36:47.780541Z","shell.execute_reply":"2022-09-04T04:36:57.507902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# result = pd.DataFrame({'patient_id':samples['patient_id'],'CE': pred[:,0],'LAA': 1-pred[:,0]}).groupby(\"patient_id\").mean()\n# submission = result[[\"CE\", \"LAA\"]].round(6).reset_index()\n# submission","metadata":{"execution":{"iopub.status.busy":"2022-09-04T04:36:57.511755Z","iopub.execute_input":"2022-09-04T04:36:57.512153Z","iopub.status.idle":"2022-09-04T04:36:57.545096Z","shell.execute_reply.started":"2022-09-04T04:36:57.512122Z","shell.execute_reply":"2022-09-04T04:36:57.543709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"# submission.to_csv('./submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-08-23T03:50:16.061415Z","iopub.execute_input":"2022-08-23T03:50:16.061830Z","iopub.status.idle":"2022-08-23T03:50:16.073802Z","shell.execute_reply.started":"2022-08-23T03:50:16.061795Z","shell.execute_reply":"2022-08-23T03:50:16.072766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}