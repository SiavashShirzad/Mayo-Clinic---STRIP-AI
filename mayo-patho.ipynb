{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import openslide\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport cv2\nimport ast\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow_addons as tfa","metadata":{"execution":{"iopub.status.busy":"2022-10-05T16:04:24.229922Z","iopub.execute_input":"2022-10-05T16:04:24.230426Z","iopub.status.idle":"2022-10-05T16:04:24.241821Z","shell.execute_reply.started":"2022-10-05T16:04:24.230385Z","shell.execute_reply":"2022-10-05T16:04:24.240583Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/mayo-clinic-strip-ai/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-10-05T16:04:24.712322Z","iopub.execute_input":"2022-10-05T16:04:24.712745Z","iopub.status.idle":"2022-10-05T16:04:24.727134Z","shell.execute_reply.started":"2022-10-05T16:04:24.712701Z","shell.execute_reply":"2022-10-05T16:04:24.725920Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df['label'] = df['label'].apply(lambda x: 1 if x == 'CE' else 0)","metadata":{"execution":{"iopub.status.busy":"2022-10-05T16:04:24.755045Z","iopub.execute_input":"2022-10-05T16:04:24.755764Z","iopub.status.idle":"2022-10-05T16:04:24.767992Z","shell.execute_reply.started":"2022-10-05T16:04:24.755725Z","shell.execute_reply":"2022-10-05T16:04:24.766872Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df = df.set_index('image_id')","metadata":{"execution":{"iopub.status.busy":"2022-10-05T16:04:24.773645Z","iopub.execute_input":"2022-10-05T16:04:24.774278Z","iopub.status.idle":"2022-10-05T16:04:24.781739Z","shell.execute_reply.started":"2022-10-05T16:04:24.774244Z","shell.execute_reply":"2022-10-05T16:04:24.780871Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"samples = pd.read_csv('../input/mayo-clinic-strip-ai/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-10-05T16:04:24.802110Z","iopub.execute_input":"2022-10-05T16:04:24.802721Z","iopub.status.idle":"2022-10-05T16:04:24.811077Z","shell.execute_reply.started":"2022-10-05T16:04:24.802678Z","shell.execute_reply":"2022-10-05T16:04:24.810128Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"final_data= pd.read_csv('../input/pathnavv2/navigation_v2.csv')\nfinal_data = final_data.set_index('Unnamed: 0')\nfinal_data = final_data.astype(object)","metadata":{"execution":{"iopub.status.busy":"2022-10-05T16:04:24.834141Z","iopub.execute_input":"2022-10-05T16:04:24.834953Z","iopub.status.idle":"2022-10-05T16:04:25.586841Z","shell.execute_reply.started":"2022-10-05T16:04:24.834919Z","shell.execute_reply":"2022-10-05T16:04:25.585749Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def get_patch(path, tl_pixel, patch_shape):\n    img = openslide.open_slide(path)\n    img = np.array(img.read_region(tl_pixel, 0, patch_shape).convert(\"RGB\"))\n    return img/255.0","metadata":{"execution":{"iopub.status.busy":"2022-10-05T16:04:26.019448Z","iopub.execute_input":"2022-10-05T16:04:26.019815Z","iopub.status.idle":"2022-10-05T16:04:26.025187Z","shell.execute_reply.started":"2022-10-05T16:04:26.019783Z","shell.execute_reply":"2022-10-05T16:04:26.024133Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# def get_patch2(os_obj, tl_pixel, patch_shape):\n#     return np.array(os_obj.read_region(tl_pixel, 0, patch_shape).convert(\"RGB\"))\n\n# final_data = pd.DataFrame()\n# ids = []\n# for n in range(df.shape[0]):\n#     img_path = \"../input/mayo-clinic-strip-ai/train/\"+df.iloc[n]['image_id']+\".tif\"\n#     label = df.iloc[n]['label']\n#     i_id  = df.iloc[n]['image_id']\n#     ids.append(i_id)\n#     img  = openslide.open_slide(img_path)\n#     series = pd.Series()\n#     print(n)\n#     for i in range(img.dimensions[0]//20,img.dimensions[0]-img.dimensions[0]//20,512):\n#         for j in range(img.dimensions[0]//20,img.dimensions[0]-img.dimensions[0]//20,512):\n#             im = get_patch2(img , (i,j), (512,512) )\n#             if im.std()>15.0:\n#                 s = pd.Series(data = [(i,j)])\n#                 series = series.append(s,ignore_index=True)\n#                 series = series.reset_index()\n#                 series = series.drop(\"index\",axis=1)\n#     final_data = pd.concat([final_data , series],axis=1)\n#     final_data.columns = ids\n","metadata":{"execution":{"iopub.status.busy":"2022-10-05T16:04:26.643032Z","iopub.execute_input":"2022-10-05T16:04:26.643705Z","iopub.status.idle":"2022-10-05T16:04:26.648812Z","shell.execute_reply.started":"2022-10-05T16:04:26.643666Z","shell.execute_reply":"2022-10-05T16:04:26.647378Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def data_gen(df = df , data = final_data):\n    for i in range(0,650):\n        n_images = 2771 - final_data.iloc[i].isnull().sum()\n        if n_images <5:\n            continue\n        label = df.loc[final_data.index[i]]['label']\n        if label == 0 :\n            images_list = np.arange(n_images)\n            for x in range(3):\n                final_image_list = np.random.choice(images_list, size=(5), replace=False)\n                img1 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[0]]),(512,512))\n                img2 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[1]]),(512,512))\n                img3 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[2]]),(512,512))\n                img4 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[3]]),(512,512))\n                img5 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[4]]),(512,512))\n                yield ({'input_71':img1,'input_72':img2,'input_73':img3,'input_74':img4,'input_75':img5},label)\n        else:\n            images_list = np.arange(n_images)\n            for x in range(1):\n                final_image_list = np.random.choice(images_list, size=(5), replace=False)\n                img1 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[0]]),(512,512))\n                img2 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[1]]),(512,512))\n                img3 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[2]]),(512,512))\n                img4 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[3]]),(512,512))\n                img5 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[4]]),(512,512))\n                yield ({'input_71':img1,'input_72':img2,'input_73':img3,'input_74':img4,'input_75':img5},label)\n       \n    \n    \ndef test_gen(df = df , data = final_data):\n    for i in range(650,754):\n        n_images = 2771 - final_data.iloc[i].isnull().sum()\n        if n_images <5:\n            continue\n        label = df.loc[final_data.index[i]]['label']\n        if label == 0 :\n            images_list = np.arange(n_images)\n            final_image_list = np.random.choice(images_list, size=(5), replace=False)\n            img1 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[0]]),(512,512))\n            img2 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[1]]),(512,512))\n            img3 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[2]]),(512,512))\n            img4 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[3]]),(512,512))\n            img5 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[4]]),(512,512))\n            yield ({'input_71':img1,'input_72':img2,'input_73':img3,'input_74':img4,'input_75':img5},label)\n        else:\n            images_list = np.arange(n_images)\n            final_image_list = np.random.choice(images_list, size=(5), replace=False)\n            img1 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[0]]),(512,512))\n            img2 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[1]]),(512,512))\n            img3 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[2]]),(512,512))\n            img4 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[3]]),(512,512))\n            img5 = get_patch('../input/mayo-clinic-strip-ai/train/'+final_data.index[i]+'.tif' , ast.literal_eval(final_data.iloc[i][final_image_list[4]]),(512,512))\n            yield ({'input_71':img1,'input_72':img2,'input_73':img3,'input_74':img4,'input_75':img5},label)","metadata":{"execution":{"iopub.status.busy":"2022-10-05T16:04:26.995405Z","iopub.execute_input":"2022-10-05T16:04:26.995752Z","iopub.status.idle":"2022-10-05T16:04:27.021586Z","shell.execute_reply.started":"2022-10-05T16:04:26.995722Z","shell.execute_reply":"2022-10-05T16:04:27.020558Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"dataset = tf.data.Dataset.from_generator(\n     data_gen,\n     ({'input_71':tf.float32,'input_72':tf.float32,'input_73':tf.float32,'input_74':tf.float32,'input_75':tf.float32}, tf.float32),\n    ({'input_71':tf.TensorShape([512,512,3]),'input_72':tf.TensorShape([512,512,3]),'input_73':tf.TensorShape([512,512,3]),'input_74':tf.TensorShape([512,512,3]),'input_75':tf.TensorShape([512,512,3])}, tf.TensorShape([]))\n)\ntestset = tf.data.Dataset.from_generator(\n     test_gen,\n     ({'input_71':tf.float32,'input_72':tf.float32,'input_73':tf.float32,'input_74':tf.float32,'input_75':tf.float32}, tf.float32),\n    ({'input_71':tf.TensorShape([512,512,3]),'input_72':tf.TensorShape([512,512,3]),'input_73':tf.TensorShape([512,512,3]),'input_74':tf.TensorShape([512,512,3]),'input_75':tf.TensorShape([512,512,3])}, tf.TensorShape([]))\n)","metadata":{"execution":{"iopub.status.busy":"2022-10-05T16:04:27.598745Z","iopub.execute_input":"2022-10-05T16:04:27.599122Z","iopub.status.idle":"2022-10-05T16:04:27.646274Z","shell.execute_reply.started":"2022-10-05T16:04:27.599090Z","shell.execute_reply":"2022-10-05T16:04:27.645356Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"\ndataset = dataset.batch(2)\ndataset=dataset.prefetch(1)\ndataset = dataset.shuffle(buffer_size = 10, seed=3)\ntestset = testset.batch(2)\ntestset=testset.prefetch(1)","metadata":{"execution":{"iopub.status.busy":"2022-10-05T16:04:28.133598Z","iopub.execute_input":"2022-10-05T16:04:28.134155Z","iopub.status.idle":"2022-10-05T16:04:28.144126Z","shell.execute_reply.started":"2022-10-05T16:04:28.134123Z","shell.execute_reply":"2022-10-05T16:04:28.143119Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"efficient = tf.keras.applications.EfficientNetB7(\n    include_top=False,\n    weights='imagenet',\n    input_tensor=None,\n    input_shape=(512,512,3),\n    pooling=None,\n)\ndef augmentation(A):\n    A = tf.keras.layers.RandomFlip()(A)\n    A =tf.keras.layers.RandomRotation(\n        (-0.2, 0.2),\n        fill_mode='reflect',\n        interpolation='bilinear',\n        seed=None,\n        fill_value=0.0,\n    )(A)\n    A = tf.keras.layers.RandomZoom(\n        (-0.1,0.1),\n        (-0.1,0.1),\n        fill_mode='reflect',\n        interpolation='bilinear',\n        seed=None,\n        fill_value=0.0,\n    )(A)\n    return A","metadata":{"execution":{"iopub.status.busy":"2022-10-05T16:04:28.949853Z","iopub.execute_input":"2022-10-05T16:04:28.950687Z","iopub.status.idle":"2022-10-05T16:04:34.868761Z","shell.execute_reply.started":"2022-10-05T16:04:28.950653Z","shell.execute_reply":"2022-10-05T16:04:34.867753Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"inputA = keras.layers.Input(shape=(512,512,3),name='input_71')\ninputB = keras.layers.Input(shape=(512,512,3),name='input_72')\ninputC = keras.layers.Input(shape=(512,512,3),name='input_73')\ninputD = keras.layers.Input(shape=(512,512,3),name='input_74')\ninputE = keras.layers.Input(shape=(512,512,3),name='input_75')\n\nA = augmentation(inputA)\nA = efficient(A)\nA = keras.models.Model(inputs=inputA, outputs=A)\nB = augmentation(inputB)\nB = efficient(B)\nB = keras.models.Model(inputs=inputB, outputs=B)\nC = augmentation(inputC)\nC = efficient(C)\nC = keras.models.Model(inputs=inputC, outputs=C)\nD = efficient(inputD)\nD = keras.models.Model(inputs=inputD, outputs=D)\nE = efficient(inputE)\nE = keras.models.Model(inputs=inputE, outputs=E)\n\nX = keras.layers.Concatenate(axis=-1)([A.output, B.output, C.output, D.output, E.output])\nX = keras.layers.Conv2D(1024, 4, strides=(4,4))(X)\nX = keras.layers.Flatten()(X)\nX = keras.layers.BatchNormalization()(X)\n\nX = keras.layers.Dense(512 ,activation = 'relu')(X)\nX = keras.layers.Dense(512 ,activation = 'relu')(X)\nX = keras.layers.Dense(128 ,activation = 'relu')(X)\nX = keras.layers.Dense(32 ,activation = 'relu')(X)\nX = keras.layers.Dense(1 ,activation = 'sigmoid')(X)\n                                               \nmodel = keras.models.Model(inputs=[A.input,B.input,C.input,D.input,E.input], outputs=X)","metadata":{"execution":{"iopub.status.busy":"2022-10-05T16:08:00.075143Z","iopub.execute_input":"2022-10-05T16:08:00.075521Z","iopub.status.idle":"2022-10-05T16:08:09.894528Z","shell.execute_reply.started":"2022-10-05T16:08:00.075493Z","shell.execute_reply":"2022-10-05T16:08:09.893543Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"for layer in model.layers[:-8]:\n    layer.trainable = False\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-10-05T16:08:09.896682Z","iopub.execute_input":"2022-10-05T16:08:09.897085Z","iopub.status.idle":"2022-10-05T16:08:09.955858Z","shell.execute_reply.started":"2022-10-05T16:08:09.897033Z","shell.execute_reply":"2022-10-05T16:08:09.954823Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Model: \"model_29\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_71 (InputLayer)           [(None, 512, 512, 3) 0                                            \n__________________________________________________________________________________________________\ninput_72 (InputLayer)           [(None, 512, 512, 3) 0                                            \n__________________________________________________________________________________________________\ninput_73 (InputLayer)           [(None, 512, 512, 3) 0                                            \n__________________________________________________________________________________________________\nrandom_flip_12 (RandomFlip)     (None, 512, 512, 3)  0           input_71[0][0]                   \n__________________________________________________________________________________________________\nrandom_flip_13 (RandomFlip)     (None, 512, 512, 3)  0           input_72[0][0]                   \n__________________________________________________________________________________________________\nrandom_flip_14 (RandomFlip)     (None, 512, 512, 3)  0           input_73[0][0]                   \n__________________________________________________________________________________________________\nrandom_rotation_12 (RandomRotat (None, 512, 512, 3)  0           random_flip_12[0][0]             \n__________________________________________________________________________________________________\nrandom_rotation_13 (RandomRotat (None, 512, 512, 3)  0           random_flip_13[0][0]             \n__________________________________________________________________________________________________\nrandom_rotation_14 (RandomRotat (None, 512, 512, 3)  0           random_flip_14[0][0]             \n__________________________________________________________________________________________________\nrandom_zoom_12 (RandomZoom)     (None, 512, 512, 3)  0           random_rotation_12[0][0]         \n__________________________________________________________________________________________________\nrandom_zoom_13 (RandomZoom)     (None, 512, 512, 3)  0           random_rotation_13[0][0]         \n__________________________________________________________________________________________________\nrandom_zoom_14 (RandomZoom)     (None, 512, 512, 3)  0           random_rotation_14[0][0]         \n__________________________________________________________________________________________________\ninput_74 (InputLayer)           [(None, 512, 512, 3) 0                                            \n__________________________________________________________________________________________________\ninput_75 (InputLayer)           [(None, 512, 512, 3) 0                                            \n__________________________________________________________________________________________________\nefficientnetb7 (Functional)     (None, 16, 16, 2560) 64097687    random_zoom_12[0][0]             \n                                                                 random_zoom_13[0][0]             \n                                                                 random_zoom_14[0][0]             \n                                                                 input_74[0][0]                   \n                                                                 input_75[0][0]                   \n__________________________________________________________________________________________________\nconcatenate_4 (Concatenate)     (None, 16, 16, 12800 0           efficientnetb7[15][0]            \n                                                                 efficientnetb7[16][0]            \n                                                                 efficientnetb7[17][0]            \n                                                                 efficientnetb7[18][0]            \n                                                                 efficientnetb7[19][0]            \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 4, 4, 1024)   209716224   concatenate_4[0][0]              \n__________________________________________________________________________________________________\nflatten_4 (Flatten)             (None, 16384)        0           conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 16384)        65536       flatten_4[0][0]                  \n__________________________________________________________________________________________________\ndense_20 (Dense)                (None, 512)          8389120     batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\ndense_21 (Dense)                (None, 512)          262656      dense_20[0][0]                   \n__________________________________________________________________________________________________\ndense_22 (Dense)                (None, 128)          65664       dense_21[0][0]                   \n__________________________________________________________________________________________________\ndense_23 (Dense)                (None, 32)           4128        dense_22[0][0]                   \n__________________________________________________________________________________________________\ndense_24 (Dense)                (None, 1)            33          dense_23[0][0]                   \n==================================================================================================\nTotal params: 282,601,048\nTrainable params: 218,470,593\nNon-trainable params: 64,130,455\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-10-05T15:44:47.034001Z","iopub.execute_input":"2022-10-05T15:44:47.034360Z","iopub.status.idle":"2022-10-05T15:44:47.039720Z","shell.execute_reply.started":"2022-10-05T15:44:47.034330Z","shell.execute_reply":"2022-10-05T15:44:47.038635Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"opt = tfa.optimizers.AdamW(\n    weight_decay=1e-4,\n    learning_rate = 0.0004,\n    beta_1 = 0.9,\n    beta_2 = 0.999,\n    epsilon = 1e-07,\n    name = 'AdamW',\n)\nloss = tf.keras.losses.BinaryCrossentropy(\n    reduction=tf.keras.losses.Reduction.AUTO,\n    name='binary_crossentropy'\n)","metadata":{"execution":{"iopub.status.busy":"2022-10-05T16:08:30.669641Z","iopub.execute_input":"2022-10-05T16:08:30.670037Z","iopub.status.idle":"2022-10-05T16:08:30.676345Z","shell.execute_reply.started":"2022-10-05T16:08:30.670006Z","shell.execute_reply":"2022-10-05T16:08:30.675246Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=opt,\n              loss=loss,\n                metrics=[tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), tf.keras.metrics.AUC()])","metadata":{"execution":{"iopub.status.busy":"2022-10-05T16:08:30.940809Z","iopub.execute_input":"2022-10-05T16:08:30.941424Z","iopub.status.idle":"2022-10-05T16:08:30.973257Z","shell.execute_reply.started":"2022-10-05T16:08:30.941385Z","shell.execute_reply":"2022-10-05T16:08:30.972484Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"!mkdir model2","metadata":{"execution":{"iopub.status.busy":"2022-10-05T16:08:32.442162Z","iopub.execute_input":"2022-10-05T16:08:32.442629Z","iopub.status.idle":"2022-10-05T16:08:33.450516Z","shell.execute_reply.started":"2022-10-05T16:08:32.442593Z","shell.execute_reply":"2022-10-05T16:08:33.449162Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"model_checkpoint_callback_LASSO = tf.keras.callbacks.ModelCheckpoint(\n    filepath = './model2/model',\n    monitor=\"val_loss\",\n    save_best_only=True,\n    save_weights_only=True,\n    mode=\"auto\",\n)","metadata":{"execution":{"iopub.status.busy":"2022-10-05T16:08:33.453889Z","iopub.execute_input":"2022-10-05T16:08:33.455095Z","iopub.status.idle":"2022-10-05T16:08:33.460898Z","shell.execute_reply.started":"2022-10-05T16:08:33.455033Z","shell.execute_reply":"2022-10-05T16:08:33.459911Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"H = model.fit(dataset, validation_data=testset, epochs=10, callbacks=[model_checkpoint_callback_LASSO])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir best_model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('./model3/model').expect_partial()\nmodel.save('./best_model/model')","metadata":{},"execution_count":null,"outputs":[]}]}